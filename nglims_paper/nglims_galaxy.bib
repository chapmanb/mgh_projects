
@article{goecks_galaxy:_2010,
	title = {Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences},
	volume = {11},
	issn = {1465-6906},
	shorttitle = {Galaxy},
	doi = {10.1186/gb-2010-11-8-r86},
	abstract = {Increased reliance on computational approaches in the life sciences has revealed grave concerns about how accessible and reproducible computation-reliant results truly are. Galaxy http://usegalaxy.org, an open web-based platform for genomic research, addresses these problems. Galaxy automatically tracks and manages data provenance and provides support for capturing the context and intent of computational methods. Galaxy Pages are interactive, web-based documents that provide users with a medium to communicate a complete computational analysis.},
	number = {8},
	author = {Jeremy Goecks and Anton Nekrutenko and James Taylor},
	year = {2010},
	note = {{PMID:} 20738864
{PMCID:} 2945788},
	pages = {R86--R86}
},

@misc{_picard_????,
	title = {Picard},
	url = {http://picard.sourceforge.net/},
	howpublished = {http://picard.sourceforge.net/}
},

@article{langmead_ultrafast_2009,
	title = {Ultrafast and memory-efficient alignment of short {DNA} sequences to the human genome},
	volume = {10},
	issn = {1465-6906},
	doi = {10.1186/gb-2009-10-3-r25},
	abstract = {Bowtie: a new ultrafast memory-efficient tool for the alignment of short {DNA} sequence reads to large genomes.

Bowtie is an ultrafast, memory-efficient alignment program for aligning short {DNA} sequence reads to large genomes. For the human genome, {Burrows-Wheeler} indexing allows Bowtie to align more than 25 million reads per {CPU} hour with a memory footprint of approximately 1.3 gigabytes. Bowtie extends previous {Burrows-Wheeler} techniques with a novel quality-aware backtracking algorithm that permits mismatches. Multiple processor cores can be used simultaneously to achieve even greater alignment speeds. Bowtie is open source .},
	number = {3},
	journal = {Genome Biology},
	author = {Ben Langmead and Cole Trapnell and Mihai Pop and Steven L Salzberg},
	year = {2009},
	note = {{PMID:} 19261174
{PMCID:} 2690996},
	pages = {R25--R25}
},

@article{mckenna_genome_2010,
	title = {The Genome Analysis Toolkit: a {MapReduce} framework for analyzing next-generation {DNA} sequencing data},
	volume = {20},
	issn = {1549-5469},
	shorttitle = {The Genome Analysis Toolkit},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20644199},
	doi = {10.1101/gr.107524.110},
	abstract = {Next-generation {DNA} sequencing {(NGS)} projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, the massive data sets generated by {NGS--the} 1000 Genome pilot alone includes nearly five terabases--make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated individuals. Indeed, many professionals are limited in the scope and the ease with which they can answer scientific questions by the complexity of accessing and manipulating the data produced by these machines. Here, we discuss our Genome Analysis Toolkit {(GATK),} a structured programming framework designed to ease the development of efficient and robust analysis tools for next-generation {DNA} sequencers using the functional programming philosophy of {MapReduce.} The {GATK} provides a small but rich set of data access patterns that encompass the majority of analysis tool needs. Separating specific analysis calculations from common data management infrastructure enables us to optimize the {GATK} framework for correctness, stability, and {CPU} and memory efficiency and to enable distributed and shared memory parallelization. We highlight the capabilities of the {GATK} by describing the implementation and application of robust, scale-tolerant tools like coverage calculators and single nucleotide polymorphism {(SNP)} calling. We conclude that the {GATK} programming framework enables developers and analysts to quickly and easily write efficient and robust {NGS} tools, many of which have already been incorporated into large-scale sequencing projects like the 1000 Genomes Project and The Cancer Genome Atlas.},
	number = {9},
	journal = {Genome Research},
	author = {Aaron {McKenna} and Matthew Hanna and Eric Banks and Andrey Sivachenko and Kristian Cibulskis and Andrew Kernytsky and Kiran Garimella and David Altshuler and Stacey Gabriel and Mark Daly and Mark A {DePristo}},
	month = sep,
	year = {2010},
	note = {{PMID:} 20644199},
	keywords = {Base Sequence, Genome, genomics, Sequence Analysis, {DNA,} Software},
	pages = {1297--1303}
},

@article{cox_solexaqa:_2010,
	title = {{SolexaQA:} At-a-glance quality assessment of Illumina second-generation sequencing data},
	volume = {11},
	issn = {1471-2105},
	shorttitle = {{SolexaQA}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20875133},
	doi = {10.1186/1471-2105-11-485},
	abstract = {{{\textless}AbstractText} {Label="BACKGROUND"} {NlmCategory="BACKGROUND"{\textgreater}Illumina's} second-generation sequencing platform is playing an increasingly prominent role in modern {DNA} and {RNA} sequencing efforts. However, rapid, simple, standardized and independent measures of run quality are currently lacking, as are tools to process sequences for use in downstream applications based on read-level quality {data.{\textless}/AbstractText{\textgreater}}
{{\textless}AbstractText} {Label="RESULTS"} {NlmCategory="RESULTS"{\textgreater}We} present {SolexaQA,} a user-friendly software package designed to generate detailed statistics and at-a-glance graphics of sequence data quality both quickly and in an automated fashion. This package contains associated software to trim sequences dynamically using the quality scores of bases within individual {reads.{\textless}/AbstractText{\textgreater}}
{{\textless}AbstractText} {Label="CONCLUSION"} {NlmCategory="CONCLUSIONS"{\textgreater}The} {SolexaQA} package produces standardized outputs within minutes, thus facilitating ready comparison between flow cell lanes and machine runs, as well as providing immediate diagnostic information to guide the manipulation of sequence data for downstream {analyses.{\textless}/AbstractText{\textgreater}}},
	journal = {{BMC} Bioinformatics},
	author = {Murray P Cox and Daniel A Peterson and Patrick J Biggs},
	year = {2010},
	note = {{PMID:} 20875133},
	pages = {485}
},

@article{li_sequence_2009,
	title = {The Sequence {Alignment/Map} format and {SAMtools}},
	volume = {25},
	issn = {1367-4811},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19505943},
	doi = {10.1093/bioinformatics/btp352},
	abstract = {{SUMMARY:} The Sequence {Alignment/Map} {(SAM)} format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. {SAMtools} implements various utilities for post-processing alignments in the {SAM} format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. {AVAILABILITY:} http://samtools.sourceforge.net.},
	number = {16},
	journal = {Bioinformatics {(Oxford,} England)},
	author = {Heng Li and Bob Handsaker and Alec Wysoker and Tim Fennell and Jue Ruan and Nils Homer and Gabor Marth and Goncalo Abecasis and Richard Durbin},
	month = aug,
	year = {2009},
	note = {{PMID:} 19505943},
	keywords = {Algorithms, Base Sequence, Computational Biology, Genome, genomics, Molecular Sequence Data, Sequence Alignment, Sequence Analysis, {DNA,} Software},
	pages = {2078--2079}
},

@misc{_snpeff_????,
	title = {{snpEff}},
	url = {http://snpeff.sourceforge.net/},
	howpublished = {http://snpeff.sourceforge.net/}
},

@misc{_fastx-toolkit_????,
	title = {{FASTX-Toolkit}},
	url = {http://hannonlab.cshl.edu/fastx_toolkit/},
	howpublished = {http://hannonlab.cshl.edu/fastx\_toolkit/}
},

@article{cock_biopython:_2009,
	title = {Biopython: freely available Python tools for computational molecular biology and bioinformatics},
	volume = {25},
	issn = {1367-4811},
	shorttitle = {Biopython},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19304878},
	doi = {10.1093/bioinformatics/btp163},
	abstract = {{SUMMARY:} The Biopython project is a mature open source international collaboration of volunteer developers, providing Python libraries for a wide range of bioinformatics problems. Biopython includes modules for reading and writing different sequence file formats and multiple sequence alignments, dealing with {3D} macro molecular structures, interacting with common tools such as {BLAST,} {ClustalW} and {EMBOSS,} accessing key online databases, as well as providing numerical methods for statistical learning. {AVAILABILITY:} Biopython is freely available, with documentation and source code at (www.biopython.org) under the Biopython license.},
	number = {11},
	journal = {Bioinformatics {(Oxford,} England)},
	author = {Peter J A Cock and Tiago Antao and Jeffrey T Chang and Brad A Chapman and Cymon J Cox and Andrew Dalke and Iddo Friedberg and Thomas Hamelryck and Frank Kauff and Bartek Wilczynski and Michiel J L de Hoon},
	month = jun,
	year = {2009},
	note = {{PMID:} 19304878},
	keywords = {Computational Biology, Databases, Factual, Internet, Programming Languages, Software},
	pages = {1422--1423}
},

@article{gautier_intuitive_2010,
	title = {An intuitive Python interface for Bioconductor libraries demonstrates the utility of language translators},
	volume = {11 Suppl 12},
	issn = {1471-2105},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21210978},
	doi = {10.1186/1471-2105-11-S12-S11},
	abstract = {{{\textless}AbstractText} {Label="BACKGROUND"} {NlmCategory="BACKGROUND"{\textgreater}Computer} languages can be domain-related, and in the case of multidisciplinary projects, knowledge of several languages will be needed in order to quickly implements ideas. Moreover, each computer language has relative strong points, making some languages better suited than others for a given task to be implemented. The Bioconductor project, based on the R language, has become a reference for the numerical processing and statistical analysis of data coming from high-throughput biological assays, providing a rich selection of methods and algorithms to the research community. At the same time, Python has matured as a rich and reliable language for the agile development of prototypes or final implementations, as well as for handling large data {sets.{\textless}/AbstractText{\textgreater}}
{{\textless}AbstractText} {Label="RESULTS"} {NlmCategory="RESULTS"{\textgreater}The} data structures and functions from Bioconductor can be exposed to Python as a regular library. This allows a fully transparent and native use of Bioconductor from Python, without one having to know the R language and with only a small community of translators required to know both. To demonstrate this, we have implemented such Python representations for key infrastructure packages in Bioconductor, letting a Python programmer handle annotation data, microarray data, and next-generation sequencing {data.{\textless}/AbstractText{\textgreater}}
{{\textless}AbstractText} {Label="CONCLUSIONS"} {NlmCategory="CONCLUSIONS"{\textgreater}Bioconductor} is now not solely reserved to R users. Building a Python application using Bioconductor functionality can be done just like if Bioconductor was a Python package. Moreover, similar principles can be applied to other languages and libraries. Our Python package is available at: {http://pypi.python.org/pypi/rpy2-bioconductor-extensions/.{\textless}/AbstractText{\textgreater}}},
	journal = {{BMC} Bioinformatics},
	author = {Laurent Gautier},
	year = {2010},
	note = {{PMID:} 21210978},
	pages = {S11}
},

@misc{_pysam_????,
	title = {pysam},
	url = {http://code.google.com/p/pysam/},
	howpublished = {http://code.google.com/p/pysam/}
}